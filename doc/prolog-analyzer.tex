\documentclass[a4paper]{article}
\usepackage[english, german]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}

\title{A Statical Analysis Tool for Prolog written in Clojure}
\author{Isabel Wingen\\ \\Lehrstuhl f\"ur\\Softwaretechnik und
  Programmiersprachen\\Heinrich-Heine Universit\"at D\"usseldorf}


\newcommand{\false}{\texttt{false}}
\newcommand{\X}{\texttt{X}}
\newcommand{\listX}{\texttt{list(X)}}
\newcommand{\prologPart}{\textit{prolog\_analyzer.pl}}
\newcommand{\jarPart}{\textit{prolog-analyzer.jar}}
\newcommand{\prologAnalyzer}{\textit{Prolog Analyzer}}
\newcommand{\future}[1]{\textcolor{lightgray}{#1}}

\begin{document}
\maketitle
\tableofcontents
\newpage
\section{Summary}
Prolog does not have a full type system. We aim to fix this
gap using spec annotations.

Prolog does not distinguish between a call that yields a correct \false{} and a
call that yields \false{} because the input was not valid.
Look at the following example:
\begin{lstlisting}
  ?- member(1,[2,3,4]).
  false.

  ?- member(a,b).
  false.
\end{lstlisting}
Both calls return \false{}, but only the first one is called in a correct way.
The second one is actually a type error which is not detected by Prolog.
The two \false{} result differ greatly and carry different information.
With spec annotations, we can make these differences visible. A spec annotation
for a predicate tells us which terms are allowed as input for the predicate,
and thus, calls with the wrong kind of terms can be marked as invalid.

A possible spec for \texttt{member/2} is \texttt{member(X,list(X))}, meaning
that the first argument is of type \X{} and the second is of type \listX{}.


The spec annotations do not change the behaviour of the Prolog programm. The
analysis is done statically using abstract interpretation with the provided spec annotations.

\section{Usage}
\subsection{Installation}
Prolog Analyzer consists of two parts:
\begin{description}
\item{\prologPart{}}\hfill\\
  This Prolog file provides the annotations and spec definitons and transforms the Prolog code
  to a format that can be read by the static analyzer.
\item{\jarPart{}}\hfill\\
  This is the static analyzer written in Clojure.
\end{description}

\paragraph{Prepare Analysis}
The \prologPart{} must be placed in the source directory of the project to be
analyzed. Every file to be analysed must include the following lines:
\begin{lstlisting}
  :- use_module(term_expander,[enable_write_out,
                               declare_spec/1,
                               define_spec/2,
                               spec_pre/2,spec_post/3,
                               spec_invariant/2]).
  :- enable_write_out.
\end{lstlisting}

For better results, the self written predicates should be annotated (see
\ref{subsection:annotations}). If no annotations are provided, \prologAnalyzer{}
derives its result from the built-in predicates used.


Spec definitions and predicate annotations can be placed in an arbritrary
module, but this module must also include the lines mentioned above.

\subsection{Specs}
To describe the different types of Prolog terms we have provided some specs:
\begin{itemize}
  \item{\texttt{any}} allows any valiue
  \item{\texttt{atomic}} allows atomic values
  \item{\texttt{integer}} allows integer values
  \item{\texttt{float}} allows float values
  \item{\texttt{number}} allows any number values
  \item{\texttt{atom}} allows any atom
  \item{\texttt{var}} allows variables
  \item{\texttt{nonvar}} allows nonvar terms
  \item{\texttt{ground}} allows ground trm
  \item{\texttt{compound(X)}} allows terms with a given functor and arity, as well as
    given spec for its arguments. For example
    \texttt{compound(int\_wrapper(int))} will allow \texttt{int\_wrapper(2)}, but
    not \texttt{int\_wrapper(pi)} or \texttt{2}. 
  \item{\texttt{list(X)}} allows homogeneous lists whose member are of type
    \X{}. For example \texttt{list(int)} only allows integers as members.
  \item{\texttt{tuple}} allows heterogeneous lists of a fixed length and with given specs
    for its members. An example is \texttt{list([int,atom])}, which will accept
    \texttt{[2,foo]}, but neither \texttt{[foo,2]} or \texttt{[2, foo, bar]}.
  \item{\texttt{specvar(X)}} is a wildcard for a spec. The spec can be referred to with
    \X{}. Can be used, if two or more terms in a scope should conform to the
    same spec.
  \item{\texttt{one\_of(X)}} takes a list \X{} of other specs. Valid values hava
    to conform to \textbf{at least one of} the specs. For example, \texttt{one\_of([int,
      atom])} will accept \texttt{3} and \texttt{foo}, but not \texttt{3.5}. 
  \item{\texttt{and(X)}} takes a list \X{} of other specs. Valid values hava
    to conform to \textbf{each} of the specs. For example, \texttt{and([atomic,
      list(any)])} will only accept the empty list \texttt{[]}.
\end{itemize}
Own predicates can be created in the source file by calling \texttt{declare\_spec/1} and afterwards \texttt{define\_spec/2}, where the
first argument is the name of your spec and the second argument is an alias.
Look at the these example, where we defined the spec \texttt{atomOrInt}, which
describes terms that are atom or int, and the spec \texttt{tree(specvar(X))},
which describes a recursive tree structure:
\begin{lstlisting}
  :- declare_spec(atomOrInt).
  :- define_spec(atomOrInt,one_of([atom, int])).

  :- declare_spec(tree(specvar(X))).
  :- define_spec(tree(specvar(X)),
                 one_of([compound(nd(tree(specvar(X),
                                     specvar(X),
                                     tree(specvar(X))))),
                 exact(empty)])).
               \end{lstlisting}

         
\subsection{Annotations}
\label{subsection:annotations}
There are three types of spec annotations:
\begin{itemize}
\item{\texttt{:- spec\_pre(foo/2,[int, atom])}}\hfill\\
  These are pre conditions, which must be fulfilled when calling predicate \texttt{foo/2}.  
\item{\texttt{:- spec\_post(foo/2,[[var, atom], [int, atom]])}}\hfill\\
  If the first condition is valid when entering the predicate, the second has to
  be valid, when the predicate is done.
\item{\texttt{:- spec\_inv(foo/2,[int, atom])}}\hfill\\
  This condition must be valid during the whole execution.
\end{itemize}

More than one spec can be annotaded. If no spec is annotated, the most general
spec is assumed: Every position is \texttt{any}.

\subsection{Execution and Result}
The path of the files to be analysed are given to \prologAnalyzer{}.
Every clause is analysed in combination with a pre spec given for the predicate
it belongs to. If no pre spec is provided, \textit{any} is assumed for every
argument.

For every term a domain is collected, which holds every spec this term has to
conform to. These specs are collected from the initial prespec, from prespecs
\future{and postspec} of the called goals
\future{and from relations between the terms}.

\future{An output is returned, which mentions every term for which
no valid domain could be calculated. }

\section{Implementation}
\subsection{Approach: Statical and Abstract}
In a first version of prolog-analyzer, called plspec
(https://github.com/wysiib/plspec) the spec checking was done in Prolog during
runtime. A big advantage was, that there was no overhead like calling a second
programm. Found errors were reported when they occured during an execution. A
disadvantage was, that the programm was not checked systematically, but instead
the check was dependent on the user's calls.



So with prolog-analyzer, we tried a different approach:

Files to be analysed need to import a single, small Prolog module, which
provides the predicate for spec annotations and spec creation, and a term
expander, which writes every predicate as edn to the filesystem.


The analysis is then statically done on the written edn by a Clojure programm.
Since the reimplementation of a Prolog interpreter is very error prone and
complex, we choose an abstract interpretation approach. With abstract
interpretation, you assign each variable a domain: A value range which is valid
and sufficent for this variable. This fits very nicely with the already provided
specs.
With every predicate, which is called in the body of a predicate, we gain
knowledge about the used terms: At the moment of the call, the term must
conform to a certain spec. This spec can then be added to the domain of the
term. If at some point, the specs in the domain contradict each other, we have
found an error.

\subsection{Implementation Detail}
\subsubsection{Environment}
Using the annotations, we want to build a domain for every used term and check,
if it is always valid. To do so, we need a sufficent way to store the found
domains in an environment. At first, we chose a simple map structure, which holds a list of found
specs for every term. But this what not enough.
More often than not, relationships between terms are introduced. Relationships
can occur from the term structure:
when using \texttt{[H|T]}, we have the two relations: \texttt{H is head of
  [H|T]} and \texttt{T is tail of [H|T]}.
Predicate calls can also create relationships. Calling \texttt{A == B} means,
that \texttt{A} and \texttt{B} have the same domain.
As automatic unification is lost in the abstract interpreter, we need to
reconstruct and maintain these relationships.
A good fitting model for the environment is a graph: The terms are the nodes,
the domain is an attribute of those nodes, and the relations are the edges
between the terms labelled with the type of relationship.
We choose to use \hyperlink{https://github.com/Engelberg/ubergraph}{ubergraph}


Roughly explained, we collect every knowledge about the domains of terms
available through code and spec annotations. Using the relationships between
them, we restrict the domains further and further. If no more change happens, the analysis
is finished.

\subsubsection{Knowledge Discovery}
The first step in the analysis is the knowledge discovery. We go through the
code and the specs and collect every information available. Some minor
interpretations are done, like acknowledging that \texttt{list(int)} cannot be a
valid spec for \texttt{123}. Therefore we find some errors in this step of the
analysis.

\begin{figure}
  \caption{Analysis Example}
  \label{example:analysis}
\begin{lstlisting}
  :- spec_pre(int/1,[int]).
int(X) :-
    integer(X).


:- spec_pre(filter/2,[list(atomic),var]).
filter([X|L],X) :-
    int(X), !.
filter([_|L],X) :-
    filter(L,X).
\end{lstlisting}
\end{figure}

The analysis is done for every pair of Clause and Prespec isolated. \future{At
  the end the result of the clauses belonging to a predicate are merged together.}



\paragraph{Step 1: Gather Information From Head and Initial Spec}\hfill\\
A pre spec gives us information about the arguments that enter the clause. So we
can use the pre spec to fill a start domain for every argument. Furthermore the
head of the clause reveals the structure of the arguments or restricts its
domain. For example, when \texttt{[H|T]} is used in the head or
\texttt{list(any)} in the spec, we already know
that this term must be a list and we have to add this knowledge to our
environment.
We also memorize in our environment, which argument was used in which position
in the head \future{for future usage}.

\begin{lstlisting}
[X|L]          dom: [list(atomic)], index: 0
X              dom: [var],          index: 1

\end{lstlisting}

\paragraph{Gather Indirect Information}\hfill\\
Gained Knowledge about a term does not only affect this term, but also some
terms depending structural on it. This is the case when using lists or
compounds.
For example, \texttt{[H|T] is list(atomic)} gives us not only that \texttt{[H|T]} is list
with atomics, but additionally \texttt{H is atomic} and \texttt{T is
  list(atomic)}.
Whenever information about a compound or list term are added to the environment,
the depending terms are also processed and updated.

\begin{lstlisting}
[X|L]          dom: [list(atomic)],  index: 0
X              dom: [var, atomic],   index: 1
L              dom: [list(atomic)]
\end{lstlisting}


\paragraph{Step 2: Gather Information From the Called Goals}\hfill\\
Next we go step to step through the body of the clause. For every goal called,
we add the used arguments to our environment.
For that, we first collect the pre specs of the goal. There are two aspects
here: we need to consider every argument individually and
we have to look at the combined value of the arguments.
For the argument at position i, one of the
terms at positions i of the found pre specs must hold. We can add the
combination of these specs as a \texttt{one-of} spec to the environment.
Furthermore there must be a valid pre-spec, which is valid for all used
arguments. To cover this aspect, we add an artifical argument to the
environment. This articifal argument is a list which contains the used arguments
in the correct order. As a domain, we set a \texttt{one-of} of the found pre
specs.
Due to the list-type of the articifal term, the relationships for the single
arguments to the artifical argument are added to the environment and can be used
later on for validation.

\paragraph{Step 3: Add Structural Relationships}\hfill\\
At the end of the discovery phase, we have seen all terms used in the clause.
We can now destruct them and add inner terms as nodes (if not already added) and their
relationships to the parent term as edges to the environment.

For lists, we add the head and the tail to the environment and the relationships
\texttt{is-head} and \texttt{is-tail}. As we only work with head-tail-lists, we
need to add sublist, if the list is given in a form like \texttt{[1,2,3]}.

For compounds, we add the arguments with a relationship \texttt{at-pos} to the
environment.

\paragraph{Special Case: Var}\hfill\\
A variable term can change its type in the course of the clause. This change is
displayed in its domain: Once it gets bound, a non-var spec is added to the
domain, and the var spec that was there once can be dismissed.

But an already bound term cannot become variable. So if there are already
non-var specs in its domain, adding a var spec is an illegal action.

\paragraph{Special Case: Specvar}\hfill\\
As mentioned above, Specvars are placeholders for other specs, but they are
restricted to a scope, which means that if \texttt{specvar(X)} is used in one
pre spec and in another, it is not the same.
As the environment is not restricted to a scope, we need to assign every specvar
a unique id. Afterwards, the specvars can be added to the domains of the terms
associated with them.
How do we ensure that all these terms really conform to a single spec?
We add the specvar to the environment, and update their domain with the values
found in domains, where this specvar is used.
If the domain of the specvar becomes invalid, we have found an error.

\subsubsection{Intersection}
\subsubsection{Relationships}
\subsubsection{Fixpoint Algorithm}
\end{document}