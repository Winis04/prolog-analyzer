\documentclass[a4paper]{article}
\usepackage[english, german]{babel}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}

\title{A Statical Analysis Tool for Prolog written in Clojure}
\author{Isabel Wingen\\ \\Lehrstuhl f\"ur\\Softwaretechnik und
  Programmiersprachen\\Heinrich-Heine Universit\"at D\"usseldorf}


\newcommand{\false}{\texttt{false}}
\newcommand{\X}{\texttt{X}}
\newcommand{\listX}{\texttt{list(X)}}
\newcommand{\prologPart}{\textit{prolog\_analyzer.pl}}
\newcommand{\jarPart}{\textit{prolog-analyzer.jar}}
\newcommand{\prologAnalyzer}{\textit{Prolog Analyzer}}

\begin{document}
\maketitle
\tableofcontents
\newpage
\section{Summary}
Prolog does not have a full type system. We aim to fix this
gap using spec annotations.

Prolog does not distinguish between a call that yields a correct \false{} and a
call that yields \false{} because the input was not valid.
Look at the following example:
\begin{lstlisting}
  ?- member(1,[2,3,4]).
  false.

  ?- member(a,b).
  false.
\end{lstlisting}
Both calls return \false{}, but only the first one is called in a correct way.
The second one is actually a type error which is not detected by Prolog.
The two \false{} result differ greatly and carry different information.
With spec annotations, we can make these differences visible. A spec annotation
for a predicate tells us which terms are allowed as input for the predicate,
and thus, calls with the wrong kind of terms can be marked as invalid.

A possible spec for \texttt{member/2} is \texttt{member(X,list(X))}, meaning
that the first argument is of type \X{} and the second is of type \listX{}.


The spec annotations do not change the behaviour of the Prolog programm. The
analysis is done statically using abstract interpretation with the provided spec annotations.

\section{Usage}
\subsection{Installation}
Prolog Analyzer consists of two parts:
\begin{description}
\item{\prologPart{}}\hfill\\
  This Prolog file provides the annotations and spec definitons and transforms the Prolog code
  to a format that can be read by the static analyzer.
\item{\jarPart{}}\hfill\\
  This is the static analyzer written in Clojure.
\end{description}

\paragraph{Prepare Analysis}
The \prologPart{} must be placed in the source directory of the project to be
analyzed. Every file to be analysed must include the following lines:
\begin{lstlisting}
  :- use_module(term_expander,[enable_write_out,
                               declare_spec/1,
                               define_spec/2,
                               spec_pre/2,spec_post/3,
                               spec_invariant/2]).
  :- enable_write_out.
\end{lstlisting}

For better results, the self written predicates should be annotated (see
\ref{subsection:annotations}). If no annotations are provided, \prologAnalyzer{}
derives its result from the built-in predicates used.


Spec definitions and predicate annotations can be placed in an arbritrary
module, but this module must also include the lines mentioned above.

\subsection{Specs}
To describe the different types of Prolog terms we have provided some specs:
\begin{itemize}
  \item{\texttt{any}} allows any valiue
  \item{\texttt{atomic}} allows atomic values
  \item{\texttt{integer}} allows integer values
  \item{\texttt{float}} allows float values
  \item{\texttt{number}} allows any number values
  \item{\texttt{atom}} allows any atom
  \item{\texttt{var}} allows variables
  \item{\texttt{nonvar}} allows nonvar terms
  \item{\texttt{ground}} allows ground trm
  \item{\texttt{compound(X)}} allows terms with a given functor and arity, as well as
    given spec for its arguments. For example
    \texttt{compound(int\_wrapper(int))} will allow \texttt{int\_wrapper(2)}, but
    not \texttt{int\_wrapper(pi)} or \texttt{2}. 
  \item{\texttt{list(X)}} allows homogeneous lists whose member are of type
    \X{}. For example \texttt{list(int)} only allows integers as members.
  \item{\texttt{tuple}} allows heterogeneous lists of a fixed length and with given specs
    for its members. An example is \texttt{list([int,atom])}, which will accept
    \texttt{[2,foo]}, but neither \texttt{[foo,2]} or \texttt{[2, foo, bar]}.
  \item{\texttt{specvar(X)}} is a wildcard for a spec. The spec can be referred to with
    \X{}. Can be used, if two or more terms in a scope should conform to the
    same spec.
  \item{\texttt{one\_of(X)}} takes a list \X{} of other specs. Valid values hava
    to conform to \textbf{at least one of} the specs. For example, \texttt{one\_of([int,
      atom])} will accept \texttt{3} and \texttt{foo}, but not \texttt{3.5}. 
  \item{\texttt{and(X)}} takes a list \X{} of other specs. Valid values hava
    to conform to \textbf{each} of the specs. For example, \texttt{and([atomic,
      list(any)])} will only accept the empty list \texttt{[]}.
\end{itemize}
Own predicates can be created in the source file by calling \texttt{declare\_spec/1} and afterwards \texttt{define\_spec/2}, where the
first argument is the name of your spec and the second argument is an alias.
Look at the these example, where we defined the spec \texttt{atomOrInt}, which
describes terms that are atom or int, and the spec \texttt{tree(specvar(X))},
which describes a recursive tree structure:
\begin{lstlisting}
  :- declare_spec(atomOrInt).
  :- define_spec(atomOrInt,one_of([atom, int])).

  :- declare_spec(tree(specvar(X))).
  :- define_spec(tree(specvar(X)),
                 one_of([compound(nd(tree(specvar(X),
                                     specvar(X),
                                     tree(specvar(X))))),
                 exact(empty)])).
               \end{lstlisting}

         
\subsection{Annotations}
\label{subsection:annotations}
There are three types of spec annotations:
\begin{itemize}
\item{\texttt{:- spec\_pre(foo/2,[int, atom])}}\hfill\\
  These are pre conditions, which must be fulfilled when calling predicate \texttt{foo/2}.  
\item{\texttt{:- spec\_post(foo/2,[[var, atom], [int, atom]])}}\hfill\\
  If the first condition is valid when entering the predicate, the second has to
  be valid, when the predicate is done.
\item{\texttt{:- spec\_inv(foo/2,[int, atom])}}\hfill\\
  This condition must be valid during the whole execution.
\end{itemize}

\subsection{Execution and Result}
The path of the files to be analysed are given to \prologAnalyzer{}.
Every clause is analysed in combination with a pre spec given for the predicate
it belongs to. If no pre spec is provided, \textit{any} is assumed for every
argument.

For every term a domain is collected, which holds every spec this term has to
conform to. These specs are collected from the initial prespec, from prespecs
\textcolor{lightgray}{and postspec} of the called goals
\textcolor{lightgray}{and from relations between the terms}.

\textcolor{lightgray}{An output is returned, which mentions every term for which
no valid domain could be calculated. }

\section{Implementation}
\subsection{Approach: Statical and Abstract}
In a first version of prolog-analyzer, called plspec
(https://github.com/wysiib/plspec) the spec checking was done in Prolog during
runtime. A big advantage was, that there was no overhead like calling a second
programm. Found errors were reported when they occured during an execution. A
disadvantage was, that the programm was not checked systematically, but instead
the check was dependent on the user's calls.



So with prolog-analyzer, we tried a different approach:

Files to be analysed need to import a single, small Prolog module, which
provides the predicate for spec annotations and spec creation, and a term
expander, which writes every predicate as edn to the filesystem.


The analysis is then statically done on the written edn by a Clojure programm.
Since the reimplementation of a Prolog interpreter is very error prone and
complex, we choose an abstract interpretation approach. With abstract
interpretation, you assign each variable a domain: A value range which is valid
and sufficent for this variable. This fits very nicely with the already provided
specs.
With every predicate, which is called in the body of a predicate, we gain
knowledge about the used terms: At the moment of the call, the term must
conform to a certain spec. This spec can then be added to the domain of the
term. If at some point, the specs in the domain contradict each other, we have
found an error.

\subsection{Implementation Detail}
\subsubsection{Environment}
Using the annotations, we want to build a domain for every used term and check,
if it is always valid. To do so, we need a sufficent way to store the found
domains, an environment. At first, we chose a simple map structure, which holds a list of found
specs for every term. But this what not enough.
More often than not, relationships between terms are introduced. Relationships
can occur from the term structure:
when using \texttt{[H|T]}, we have the two relations: \texttt{H is head of
  [H|T]} and \texttt{T is tail of [H|T]}.
Predicate calls can also create relationships. Calling \texttt{A == B} means,
that \texttt{A} and \texttt{B} have the same domain.
As automatic unification is lost in the abstract interpreter, we need to
reconstruct and maintain these relationships.
A good fitting model for the environment is a graph: The terms are the nodes,
the domain is an attribute of those nodes, and the relations are the edges
between the terms labelled with the type of relationship.
We choose to use \hyperlink{https://github.com/Engelberg/ubergraph}{ubergraph}


\subsubsection{Knowledge Discovery}
To collect the 
\subsubsection{Intersection}
\subsubsection{Relationships}
\subsubsection{Fixpoint Algorithm}
\end{document}